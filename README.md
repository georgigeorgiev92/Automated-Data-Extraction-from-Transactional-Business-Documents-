Abstract
Business and documents are closely related to each other since the business depends on them for diverse legal and financially associated purposes. In fact, the rapid pace of the modern world and the constantly growing volume of documentation makes their manual processing a rather slow and tedious task.
In this work, we describe the automatic data extraction process regarding invoices (a type of transactional document frequently used in business), relevant for micro and small businesses alongside with comprehensive research of the commercial data extraction software tools currently available on the market. We describe the task of extracting data fields (e.g. invoice sender, invoiced amount, bought service or product) from the forms as well as a direct comparison between the tools concerning their characteristics and performance. The transactional documents can be heterogeneous in outline with no actual legal requirement about form and structure, which makes the task of information extraction from them challenging.
Specifically, we have evaluated the existing tools with regards to the correctness and completeness of the extracted data. For that purpose we have used the following metrics: precision (e.g. from the results classified as “sender” fields, how many are actually “sender” fields), recall (e.g. from the “sender” fields, how many of them are correctly classified as “sender” fields) as well as the F1 score, which combines the weighted average of the previous two in a harmonic mean.
To execute our evaluation, we have selected 50 invoices in English language with both familiar and unfamiliar layouts for the extraction system. Every tool’s extraction efficiency was assessed for each of the following document key fields- Sender name, Sender address, Receiver name, Receiver address, Invoice number and Invoice date.
The extracted key-value pairs from the invoice documents had to be assessed against the metrics, mentioned above. The results of the benchmark are in a form of a table and they provide answers to the following questions:
* How well the tools deal with the associated task?
* Where exactly do they tend to fail?
* How the systems differ in their configuration – what is required by the user as input?
* What factors could potentially influence the key data extraction- both negatively and positively?
* What could be improved overall?
The general conclusion was that from all of the tools included in the assessment, Parashift achieved the best results in almost every aspect. Moreover, it has accomplished the highest values of precision in 4 fields and the highest values of recall in 5 fields out of the complete 7 fields. The F1 Score was also the highest in 5 of the fields and the error rate was the lowest- only 10% or precisely 37 errors in 350 fields overall, which was almost 3 times lower as an error rate than the second tool- namely Sypht with 29 % and the third tool Google AI with 31%.
We have further analyzed the results and the specific problems that occurred in the commercial tools (such as incorrect/unrecognized extracted numerical or textual fields; sparse segmentation between entities etc.) and gave hints for possible improvements and future work.
To the best of our knowledge, such software benchmark combined with document analytics in a single study hasn’t been compiled yet. However, there are multiple papers comparing some of the competitor solutions. All of them, though, are written from the companies, which also possess such software tools and the metrics used for the comparison are different.
